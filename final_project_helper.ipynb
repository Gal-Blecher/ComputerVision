{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.linalg import null_space\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "# plt.rcParams['figure.figsize'] = (4.0, 4.0)\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(name_file):\n",
    "    cap= cv2.VideoCapture(name_file)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_video(video):\n",
    "    out = []\n",
    "    for frame in video:\n",
    "        out.append(cv2.transpose(frame))\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_gray_scale(video):\n",
    "    out = []\n",
    "    for frame in video:\n",
    "        out.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.int16))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_edges(video, L_th, H_th):\n",
    "    out = []\n",
    "    for frame in video:\n",
    "        out.append(cv2.Canny(frame, L_th, H_th))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_black_white(video):\n",
    "    out = []\n",
    "    for frame in video:\n",
    "        frame[frame < 80] = 0\n",
    "        frame[frame >= 80] = 255\n",
    "        out.append(frame)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(lst):\n",
    "    arr = np.array(lst)\n",
    "    return arr / arr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade Basic OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Deriv_Gauss_x(sigma, mask_size):\n",
    "    return np.array([[-i/(2*np.pi*sigma**4)*np.exp(-(i**2 + j**2)/(2*sigma**2)) for j in range(-mask_size, mask_size+1)] for i in range(-mask_size, mask_size+1)])\n",
    "\n",
    "def Deriv_Gauss_y(sigma, mask_size):\n",
    "    return np.array([[-j/(2*np.pi*sigma**4)*np.exp(-(i**2 + j**2)/(2*sigma**2)) for j in range(-mask_size, mask_size+1)] for i in range(-mask_size, mask_size+1)])\n",
    "\n",
    "def Grad_x(img, G_dx):\n",
    "    return convolve2d(img, G_dx, mode='same')\n",
    "\n",
    "def Grad_y(img, G_dy):\n",
    "    return convolve2d(img, G_dy, mode='same')\n",
    "\n",
    "def gauss_kernel_2d(sigma, mask_size):\n",
    "    return np.array([[1/(2 * np.pi * sigma ** 2) * np.exp(- (i**2 + j**2)/(2 * sigma ** 2)) for j in range(-mask_size, mask_size+1)] for i in range(-mask_size, mask_size+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_LK_OF(video, nf1, nf2, sigma_S, sigma_R, patch_size, scale_percent=100):\n",
    "    im1_s = np.ones((300, 300)) * 255\n",
    "    im1_s[50:100, 50:100] = 0 #frame[50:100, 50:100]\n",
    "    im2_s = np.ones((300, 300)) * 255\n",
    "    im2_s[55:105, 55:105] = 0 #frame[50:100, 50:100]\n",
    "    im1_s = video[nf1].astype(np.float32)\n",
    "    im2_s = video[nf2].astype(np.float32)\n",
    "    img1_orig = im1_s#frames[nf1]\n",
    "    img2_orig = im2_s#frames[nf2]\n",
    "    frames = [im1_s, im2_s]\n",
    "    #First smooth in temporal domain:\n",
    "#     if nf1 > 1 and nf2 > 1 and len(frames) > nf1 + 2 and len(frames) > nf2 + 2:\n",
    "#         img1 = np.average(frames[nf1-2:nf1+3], axis=0, weights=[1,4,6,4,1])\n",
    "#         img2 = np.average(frames[nf2-2:nf2+3], axis=0, weights=[1,4,6,4,1])\n",
    "#     else:\n",
    "#         img1 = frames[nf1]\n",
    "#         img2 = frames[nf2]\n",
    "    img1 = im1_s#frames[nf1] \n",
    "    img2 = im2_s#frames[nf2]\n",
    "    #resize:\n",
    "    width = int(img1.shape[1] * scale_percent / 100)\n",
    "    height = int(img1.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    img1 = cv2.resize(img1, dim, interpolation = cv2.INTER_LINEAR)\n",
    "    img2 = cv2.resize(img2, dim, interpolation = cv2.INTER_LINEAR)\n",
    "    img1_orig = cv2.resize(img1_orig, dim, interpolation = cv2.INTER_LINEAR)\n",
    "    img2_orig = cv2.resize(img2_orig, dim, interpolation = cv2.INTER_LINEAR)\n",
    "    mask_size = int(3 * sigma_S)\n",
    "    G_dx = Deriv_Gauss_x(sigma_S, mask_size)\n",
    "    G_dy = Deriv_Gauss_y(sigma_S, mask_size)\n",
    "    Ix = Grad_x(img1, G_dx)\n",
    "#     plt.imshow(Ix)\n",
    "#     plt.show();\n",
    "    Iy = Grad_y(img1, G_dy)\n",
    "#     plt.imshow(Iy)\n",
    "#     plt.show();\n",
    "    It = img2 - img1\n",
    "    gauss_kernel = gauss_kernel_2d(sigma_R, int(3 * sigma_R))\n",
    "#     gauss_kernel=np.array([[1,2,1],[2,4,2],[1,2,1]])/16\n",
    "#     print(gauss_kernel)\n",
    "    C = [convolve2d(Ix * Ix, gauss_kernel), convolve2d(gauss_kernel, Ix * Iy), convolve2d(gauss_kernel, Iy * Iy)]\n",
    "    U = np.zeros((img1.shape[0], img1.shape[1]))\n",
    "    V = np.zeros((img1.shape[0], img1.shape[1]))\n",
    "    for i in range(img1.shape[0]):\n",
    "        for j in range(img1.shape[1]):\n",
    "            c = np.array([[C[0][i][j], C[1][i][j]], [C[1][i][j], C[2][i][j]]])\n",
    "            if np.linalg.matrix_rank(c) == 2:\n",
    "                min_x = max(0, i - int(patch_size / 2))\n",
    "                max_x = min(img1.shape[0], i + int(patch_size / 2) + 1)\n",
    "                min_y = max(0, j - int(patch_size / 2))\n",
    "                max_y = min(img1.shape[1], j + int(patch_size / 2) + 1)\n",
    "                A = np.column_stack((Ix[min_x: max_x, min_y: max_y].reshape(-1, 1), Iy[min_x: max_x, min_y: max_y].reshape(-1, 1)))\n",
    "                b = -It[min_x: max_x, min_y: max_y].reshape(-1, 1)\n",
    "                u, v = np.matmul(np.linalg.pinv(A), b)\n",
    "                U[i][j] = float(u)\n",
    "                V[i][j] = float(v)\n",
    "#                 print(i)\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OF_plot_results(U,im1, skip, arrow_size):\n",
    "    x = np.arange(0, im1.shape[1], skip)\n",
    "    y = np.arange(0, im1.shape[0], skip)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    V = np.zeros(im1.shape)\n",
    "    \n",
    "    U_reduced = U[: : skip, : : skip]\n",
    "    V_reduced = V[: : skip, : : skip]\n",
    "#     print('X shape: ', X.shape)\n",
    "#     print('U_reduced shape: ', U_reduced.shape)\n",
    "    plt.figure(figsize = (30,30))\n",
    "    fig, ax = plt.subplots(figsize = (30,30))\n",
    "    ax.imshow(im1, cmap = 'gray')\n",
    "    ax.quiver( X, Y, U_reduced, -V_reduced, width = arrow_size, scale = 70, color = 'blue')\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title('OF_plot_results', fontsize = 20)\n",
    "    plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grad_o(Ix, Iy):\n",
    "    return np.arctan(Iy / Ix)\n",
    "\n",
    "def Grad_m(Ix, Iy):\n",
    "    return np.sqrt(Ix ** 2 + Iy ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thinning(G_magnitute, G_orientation):\n",
    "    G_orientation[(G_orientation <= np.pi / 8) | (G_orientation > 7 * np.pi / 8)] = 0 # horizontal\n",
    "    G_orientation[(G_orientation > np.pi / 8) & (G_orientation <= 3 * np.pi / 8)] = 1 # diagonal 45\n",
    "    G_orientation[(G_orientation > 3 * np.pi / 8) & (G_orientation <= 5 * np.pi / 8)] = 2 # vertical\n",
    "    G_orientation[(G_orientation > 5 * np.pi / 8) & (G_orientation <= 7 * np.pi / 8)] = 3 # diagonal 135\n",
    "    thin_img = np.zeros((G_magnitute.shape))\n",
    "    for i in range(1, G_magnitute.shape[0] - 1):\n",
    "        for j in range(1, G_magnitute.shape[1] - 1):\n",
    "            if G_orientation[i][j] == 0:\n",
    "                l = G_magnitute[i][j - 1]\n",
    "                r = G_magnitute[i][j + 1]\n",
    "            if G_orientation[i][j] == 1:\n",
    "                l = G_magnitute[i - 1][j + 1]\n",
    "                r = G_magnitute[i + 1][j - 1] \n",
    "            if G_orientation[i][j] == 2:\n",
    "                l = G_magnitute[i + 1][j]\n",
    "                r = G_magnitute[i - 1][j] \n",
    "            if G_orientation[i][j] == 3:\n",
    "                l = G_magnitute[i - 1][j - 1]\n",
    "                r = G_magnitute[i + 1][j + 1]\n",
    "            if G_magnitute[i][j] >= l and G_magnitute[i][j] >= r:\n",
    "                thin_img[i][j] = G_magnitute[i][j]\n",
    "    return thin_img\n",
    "\n",
    "\n",
    "def canny(img, sigma, L_th, H_th):\n",
    "    mask_size = 8  #you should compute the mask size\n",
    "    G_dx = Deriv_Gauss_x(sigma, mask_size)\n",
    "    G_dy = Deriv_Gauss_y(sigma, mask_size)\n",
    "        \n",
    "    Ix = Grad_x(img, G_dx)\n",
    "    Iy = Grad_y(img, G_dy)\n",
    "    \n",
    "    G_orientation = Grad_o(Ix, Iy)\n",
    "    G_magnitute = Grad_m(Ix, Iy)\n",
    "    \n",
    "    Et = thinning(G_magnitute, G_orientation)\n",
    "    thin_img = Et\n",
    "    thin_img = thin_img / thin_img.max()\n",
    "    high_threshold = H_th\n",
    "    low_threshold = L_th\n",
    "    \n",
    "    thin_img_high = thin_img.copy()\n",
    "    thin_img_high[thin_img_high <= high_threshold] = 0\n",
    "    thin_img_high[thin_img_high > high_threshold] = 1\n",
    "\n",
    "    thin_img_low = thin_img.copy()\n",
    "    thin_img_low[(thin_img_low < low_threshold) | (thin_img_low > high_threshold)] = 0\n",
    "    thin_img_low[(thin_img_low <= high_threshold) & (thin_img_low >= low_threshold)] = 2\n",
    "\n",
    "    sum_original = thin_img_high + thin_img_low\n",
    "    sum_original[sum_original > 0] = 1\n",
    "    kernel = np.ones((15, 15),np.uint8)\n",
    "    dilate_img_high = cv2.dilate(thin_img_high, kernel, iterations = 1)\n",
    "    dilate_and_low = dilate_img_high + thin_img_low\n",
    "    no_dilate_img = np.uint8(dilate_and_low * sum_original)\n",
    "\n",
    "    num_labels, labels  = cv2.connectedComponents(no_dilate_img, connectivity=8)\n",
    "    no_dilate_img[no_dilate_img > 0] = 1\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    for i in unique_labels:\n",
    "        idx = np.where(labels == i)\n",
    "        if (thin_img[idx] >= high_threshold).any():\n",
    "            labels[idx] = 1\n",
    "        else:\n",
    "            labels[idx] = 0\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_2 = np.ones((14,14))\n",
    "# mask_2[:, 0] = -1\n",
    "# mask_2[:, 6] = -1\n",
    "# mask_2[:, 13] = -1\n",
    "# mask_2[0, :] = -1\n",
    "# mask_2[13, :] = -1\n",
    "# mask_2[6:8, :] = -1\n",
    "# plt.imshow(mask_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(img, kernel): #img in color, kernel grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.int16)\n",
    "    window_size = kernel.shape[0]\n",
    "    window = np.ones((window_size, window_size))\n",
    "    shift = int(window_size / 2)\n",
    "    max_corr = 0\n",
    "    x_idx = 0\n",
    "    for i in range(shift, img.shape[0] - shift):\n",
    "        for j in range(shift, img.shape[1] - shift):\n",
    "#             print('window.shape: ', window.shape)\n",
    "#             print('img[i - shift : i + shift + 1, j - shift : j + shift + 1]: ', img[i - shift : i + shift + 1, j - shift : j + shift + 1])\n",
    "            v = window * img[i - shift : i + shift + 1, j - shift : j + shift + 1]\n",
    "#             print('v: ', v)\n",
    "            if np.linalg.norm(kernel) == 0 or np.linalg.norm(v) == 0:\n",
    "                continue\n",
    "#             print('kernel.shape: ', kernel.shape)\n",
    "#             print('v.shape: ', v.shape)\n",
    "            corr = np.dot(kernel.flatten(), v.flatten()) / (np.linalg.norm(kernel) * np.linalg.norm(v))\n",
    "            if corr > max_corr:\n",
    "#                 print(j)\n",
    "                max_corr = corr\n",
    "                x_idx = j\n",
    "    return x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(video, x_lim, y_lim):\n",
    "    out = []\n",
    "    for frame in video:\n",
    "        croped = frame[y_lim[0]:y_lim[1], x_lim[0]:x_lim[1]]\n",
    "        out.append(croped)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_calc(pos_arr, fps = 30):\n",
    "    count = 0\n",
    "    t = len(pos_arr)\n",
    "    if len(pos_arr) < 2:\n",
    "        return 0\n",
    "    if pos_arr[0] > pos_arr[1]:\n",
    "        count += 1\n",
    "    for i in range(0, len(pos_arr) - 1):\n",
    "        if pos_arr[i - 1] == pos_arr[i]:\n",
    "#             print(i)\n",
    "            t -= 1\n",
    "        if pos_arr[i] > pos_arr[i + 1] and pos_arr[i] > pos_arr[i - 1]:\n",
    "            count += 1\n",
    "    return count / (len(pos_arr) / fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_window(video, window):\n",
    "    s = []\n",
    "    for i in range(len(video)):\n",
    "        s.append(video[i][window[0]:window[1], window[2]:window[3]].sum())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_count(video, window, similarity_factor):\n",
    "    count = 0\n",
    "    t = len(video)\n",
    "    th = video[0][window[0]:window[1], window[2]:window[3]].sum()\n",
    "    for i in range(len(video) - 1):\n",
    "#         print(frame[window[0]:window[1], window[2]:window[3]].sum())\n",
    "        present = video[i]\n",
    "        next_frame = video[i + 1]\n",
    "        if ssim(video[i], video[i + 1]) > similarity_factor:\n",
    "            t -= 1\n",
    "            continue\n",
    "            \n",
    "        s = video[i][window[0]:window[1], window[2]:window[3]].sum()\n",
    "#         if s > 0.99 * th or s < 1.01 * th:\n",
    "#             count += 1\n",
    "        if s == th:\n",
    "            count += 1\n",
    "    return (count / (t / 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_video(video, kernel):\n",
    "    out = []\n",
    "    for i in range(len(video)):\n",
    "#         print(i)\n",
    "        out.append(track(video[i], kernel))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_far(video):\n",
    "    out = []\n",
    "    for frame in video:\n",
    "        out.append(frame.sum())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_pixel(video, pixel):\n",
    "    s = []\n",
    "    for i in range(len(video)):\n",
    "        s.append(video[i][pixel[0], pixel[1]])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_track(video, pos):\n",
    "    out = []\n",
    "    radius = 50\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 4\n",
    "    lineType = 2\n",
    "    f = 0.0\n",
    "    for i in range(len(video)):\n",
    "        if i % 3 == 0 and i > 20:\n",
    "            t = frequency_calc(pos[i - 20 : i + 20])\n",
    "            f = round(((f + t) / 2), 2) # average to reduce outliers\n",
    "#         print(f)\n",
    "        video[i] = cv2.putText(video[i],f'{f}Hz', (50,600), cv2.FONT_HERSHEY_SIMPLEX , 3, (255, 0, 0), 3)\n",
    "        center_coordinates = (int(pos[i] + 200), 340) # +200 because of the crop\n",
    "        out.append(cv2.circle(video[i], center_coordinates, radius, color, thickness))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(video, name):\n",
    "    writer = cv2.VideoWriter(name + '.mp4', cv2.VideoWriter_fourcc(*\"DIVX\"), 30,(1080, 1920))\n",
    "    for i in range(len(video)):\n",
    "        writer.write(video[i])\n",
    "    writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func(pos, video, file_name):\n",
    "    plt.figure(figsize = (15,8))\n",
    "    plt.plot(pos, 'b')\n",
    "    plt.xticks(np.arange(0, len(video), 50))\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.savefig(f'/Users/galblecher/Desktop/cv_project/plots_5/{file_name}.png')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste(main, pic):\n",
    "    main = Image.fromarray(np.uint8(main)).convert('RGB')\n",
    "    pic = Image.fromarray(np.uint8(pic)).convert('RGB')\n",
    "    main.paste(pic, (0, 1350))\n",
    "    pasted = np.array(main)\n",
    "    return pasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(pos, video):\n",
    "    for i in range(len(pos)):\n",
    "        plot_func(pos[:i], video, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_on_img(video, path):\n",
    "    out = []\n",
    "    for i in range(len(video)): \n",
    "        plot = cv2.imread(path + f'/{i}' + '.png')\n",
    "        main = video[i]\n",
    "        out.append(paste(main, plot))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(lst, name):\n",
    "    with open(name + \".txt\", \"w\") as f:\n",
    "        for l in lst:\n",
    "            f.write(str(l) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_track_rectangle(video, pos):\n",
    "    out = []\n",
    "    start_point = (100, 400) \n",
    "    end_point = (550, 750)\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 4\n",
    "    lineType = 2\n",
    "    f = 0.0\n",
    "    for i in range(len(video)):\n",
    "        if i % 3 == 0 and i > 20:\n",
    "            t = frequency_calc(pos[i - 20 : i + 20])\n",
    "            f = round(((f + t) / 2), 2) # average to reduce outliers\n",
    "#         print(f)\n",
    "        video[i] = cv2.putText(video[i],f'{f}Hz', (50,300), cv2.FONT_HERSHEY_SIMPLEX , 3, (255, 0, 0), 3)\n",
    "        out.append(cv2.rectangle(video[i], start_point, end_point, color, thickness))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_track_arrow(video, pos):\n",
    "    out = []\n",
    "    start_point = (645, 100) \n",
    "    end_point = (753, 200)\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 4\n",
    "    lineType = 2\n",
    "    f = 0.0\n",
    "    for i in range(len(video)):\n",
    "        if i % 3 == 0 and i > 20:\n",
    "            t = frequency_calc(pos[i - 20 : i + 20])\n",
    "            f = round(((f + t) / 2), 2) # average to reduce outliers\n",
    "#         print(f)\n",
    "        video[i] = cv2.putText(video[i],f'{f}Hz', (50,600), cv2.FONT_HERSHEY_SIMPLEX , 3, (255, 0, 0), 3)\n",
    "        video[i] = cv2.putText(video[i],f'The pixel ', (450, 100), cv2.FONT_HERSHEY_SIMPLEX , 1.5, (255, 0, 0), 3)\n",
    "        out.append(cv2.arrowedLine(video[i], start_point, end_point, color, thickness))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_from_frame(frame):\n",
    "    video = []\n",
    "    for i in range(60):\n",
    "        video.append(frame)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
